{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apify_client import ApifyClient\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "\n",
    "# Initialize the ApifyClient with your API token\n",
    "# client = ApifyClient(os.getenv('APIFY_kEY'))\n",
    "\n",
    "# # Prepare the Actor input\n",
    "# run_input = {\n",
    "#     \"queries\": \"\"\"javascript\n",
    "#                 typescript\n",
    "#                 python\"\"\",\n",
    "#     \"resultsPerPage\": 100,\n",
    "#     \"maxPagesPerQuery\": 1,\n",
    "#     \"languageCode\": \"\",\n",
    "#     \"forceExactMatch\": False,\n",
    "#     \"wordsInTitle\": [],\n",
    "#     \"wordsInText\": [],\n",
    "#     \"wordsInUrl\": [],\n",
    "#     \"mobileResults\": False,\n",
    "#     \"includeUnfilteredResults\": False,\n",
    "#     \"saveHtml\": False,\n",
    "#     \"saveHtmlToKeyValueStore\": True,\n",
    "#     \"includeIcons\": False,\n",
    "# }\n",
    "\n",
    "# # Run the Actor and wait for it to finish\n",
    "# run = client.actor(\"nFJndFXA5zjCTuudP\").call(run_input=run_input)\n",
    "\n",
    "# # Fetch and print Actor results from the run's dataset (if there are any)\n",
    "# for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "    # print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:                                               #debug  #error  \\\n",
      "0  {'requestId': 'jOJi5Yl6FoNLXH4', 'url': 'http:...   False   \n",
      "1  {'requestId': 'XvD3XiAusaTNex9', 'url': 'http:...   False   \n",
      "2  {'requestId': '3zuQsbtbqbKrFZh', 'url': 'http:...   False   \n",
      "\n",
      "                                         searchQuery  \\\n",
      "0  {'term': 'real estate', 'url': 'http://www.goo...   \n",
      "1  {'term': 'housing properties', 'url': 'http://...   \n",
      "2  {'term': 'constructions', 'url': 'http://www.g...   \n",
      "\n",
      "                                                 url  hasNextPage  \\\n",
      "0  http://www.google.com/search?q=real+estate&hl=...         True   \n",
      "1  http://www.google.com/search?q=housing+propert...         True   \n",
      "2  http://www.google.com/search?q=constructions&h...         True   \n",
      "\n",
      "  serpProviderCode  resultsTotal  \\\n",
      "0                L    6220000000   \n",
      "1                L     846000000   \n",
      "2                L    3090000000   \n",
      "\n",
      "                                      relatedQueries paidResults paidProducts  \\\n",
      "0  [{'title': 'real estate - deutsch', 'url': 'ht...          []           []   \n",
      "1  [{'title': 'Affordable housing', 'url': 'https...          []           []   \n",
      "2  [{'title': 'Konstruktion (Construction)Studien...          []           []   \n",
      "\n",
      "                                      organicResults suggestedResults  \\\n",
      "0  [{'title': 'Zillow: Real Estate, Apartments, M...               []   \n",
      "1  [{'title': 'AffordableHousing.com - Affordable...               []   \n",
      "2  [{'title': 'Constructions', 'url': 'https://ww...               []   \n",
      "\n",
      "  peopleAlsoAsk customData                                    htmlSnapshotUrl  \n",
      "0            []       None  https://api.apify.com/v2/key-value-stores/FFMq...  \n",
      "1            []       None  https://api.apify.com/v2/key-value-stores/FFMq...  \n",
      "2            []       None  https://api.apify.com/v2/key-value-stores/FFMq...  \n"
     ]
    }
   ],
   "source": [
    "# from apify_client import ApifyClient\n",
    "\n",
    "# # You can find your API token at https://console.apify.com/settings/integrations.\n",
    "# TOKEN = 'MY-APIFY-TOKEN'\n",
    "\n",
    "\n",
    "# def main() -> None:\n",
    "#     apify_client = ApifyClient(TOKEN)\n",
    "\n",
    "#     # Start an Actor and wait for it to finish.\n",
    "#     actor_client = apify_client.actor('john-doe/my-cool-actor')\n",
    "#     call_result = actor_client.call()\n",
    "\n",
    "#     if call_result is None:\n",
    "#         print('Actor run failed.')\n",
    "#         return\n",
    "\n",
    "#     # Fetch results from the Actor run's default dataset.\n",
    "#     dataset_client = apify_client.dataset(call_result['defaultDatasetId'])\n",
    "#     list_items_result = dataset_client.list_items()\n",
    "#     print(f'Dataset: {list_items_result}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from apify_client import ApifyClientAsync\n",
    "import pandas as pd\n",
    "# You can find your API token at https://console.apify.com/settings/integrations.\n",
    "TOKEN = os.getenv('APIFY_KEY')\n",
    "# Prepare the Actor input\n",
    "run_input = {\n",
    "    \"queries\": \"\"\"real estate\n",
    "                constructions\n",
    "                housing properties\"\"\",\n",
    "    \"resultsPerPage\": 2,\n",
    "    \"maxPagesPerQuery\": 1,\n",
    "    \"languageCode\": \"de\",\n",
    "    \"forceExactMatch\": False,\n",
    "    \"wordsInTitle\": [],\n",
    "    \"wordsInText\": [],\n",
    "    \"wordsInUrl\": [],\n",
    "    \"mobileResults\": False,\n",
    "    \"includeUnfilteredResults\": False,\n",
    "    \"saveHtml\": False,\n",
    "    \"saveHtmlToKeyValueStore\": True,\n",
    "    \"includeIcons\": False,\n",
    "}\n",
    "\n",
    "async def main() -> None:\n",
    "    apify_client = ApifyClientAsync(TOKEN)\n",
    "\n",
    "    # Start an Actor and wait for it to finish.\n",
    "    actor_client = apify_client.actor('apify/google-search-scraper')\n",
    "    call_result = await actor_client.call(run_input=run_input)\n",
    "\n",
    "    if call_result is None:\n",
    "        print('Actor run failed.')\n",
    "        return\n",
    "\n",
    "    # Fetch results from the Actor run's default dataset.\n",
    "    dataset_client = apify_client.dataset(call_result['defaultDatasetId'])\n",
    "    list_items_result = await dataset_client.list_items()\n",
    "    print(f'Dataset: {pd.DataFrame(list_items_result.items)}')\n",
    "    \n",
    "\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'LEONHARD WEISS Construction Company', 'link': 'https://www.leonhard-weiss.de/eng/index_en.html', 'description': \"Founded in 1900, LEONHARD WEISS is among Germany's most powerful and successful construction companies.\", 'email': 'bau-de@leonhard-weiss.com'}\n",
      "{'title': 'What is a property developer, what do they do & ...', 'link': 'https://www.mfsuk.com/blog/what-is-a-property-developer/', 'description': 'Property developers are individuals who build new properties or refurbish existing houses to sell them on for a profit.', 'email': 'info@mfsuk.com'}\n"
     ]
    }
   ],
   "source": [
    "from apify_client import ApifyClientAsync\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import logging\n",
    "from typing import List, Dict, Optional\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "class LeadGenerator:\n",
    "    def __init__(self, token: str):\n",
    "        self.client = ApifyClientAsync(token)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.apify_token = os.getenv('APIFY_TOKEN')\n",
    "        self.email_config = {\n",
    "            'sender': os.getenv('SENDER_EMAIL'),\n",
    "            'password': os.getenv('EMAIL_PASSWORD'),\n",
    "            'smtp_server': 'smtp.gmail.com',\n",
    "            'port': 465\n",
    "        }\n",
    "        \n",
    "            \n",
    "    async def fetch_search_results(self, keywords: List[str]) -> Optional[pd.DataFrame]:\n",
    "        query = \"\\n\".join(keywords)\n",
    "        run_input = {\n",
    "            \"queries\": query,\n",
    "            \"resultsPerPage\": 2,\n",
    "            \"maxPagesPerQuery\": 1,\n",
    "            \"languageCode\": \"de\",\n",
    "            \"countryCode\": 'de',\n",
    "            # ... rest of config\n",
    "        }\n",
    "        try:\n",
    "            actor_client = self.client.actor('apify/google-search-scraper')\n",
    "            call_result = await actor_client.call(run_input=run_input)\n",
    "            if not call_result:\n",
    "                raise ValueError('Search actor run failed')\n",
    "                \n",
    "            dataset_client = self.client.dataset(call_result['defaultDatasetId'])\n",
    "            async for item in dataset_client.iterate_items():\n",
    "                for result in item.get('organicResults', []):\n",
    "                    yield {\n",
    "                        'title': result.get('title', ''),\n",
    "                        'link': result.get('url', ''),\n",
    "                        'description': result.get('description', ''),\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error fetching search results: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "class ContactGenerator:\n",
    "    def __init__(self, token: str):\n",
    "        self.client = ApifyClientAsync(token)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "            \n",
    "    async def fetch_contact_results(self, url: str) -> Optional[pd.DataFrame]:\n",
    "        # query = \"\\n\".join(keywords)\n",
    "        run_input = {\n",
    "            \"startUrls\": [{ \"url\": url }],\n",
    "            \"maxRequestsPerStartUrl\": 1,\n",
    "            \"maxDepth\": 5,\n",
    "            \"maxRequests\": 9999999,\n",
    "            \"sameDomain\": True,\n",
    "            \"considerChildFrames\": True,\n",
    "            \"useBrowser\": False,\n",
    "            \"waitUntil\": \"domcontentloaded\",\n",
    "            \"proxyConfig\": { \"useApifyProxy\": True },\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            actor_client = self.client.actor('vdrmota/contact-info-scraper')\n",
    "            call_result = await actor_client.call(run_input=run_input)\n",
    "            if not call_result:\n",
    "                raise ValueError('Search actor run failed')\n",
    "                \n",
    "            dataset_client = self.client.dataset(call_result['defaultDatasetId'])\n",
    "            async for item in dataset_client.iterate_items():\n",
    "                emails = item.get('emails', [])\n",
    "                if emails != []:\n",
    "                    yield {'email': emails[0]}\n",
    "                else:\n",
    "                    yield {'email': None}\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error fetching contact results: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main function to demonstrate usage.\"\"\"\n",
    "    # Initialize generators\n",
    "    token = os.getenv('APIFY_KEY')\n",
    "    lead_gen = LeadGenerator(token)\n",
    "    contact_gen = ContactGenerator(token)\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Process leads sequentially\n",
    "        async for lead_result in lead_gen.fetch_search_results(['real estate companies', 'construction companies', 'realtors', 'real estate agents', 'interior designers and decor', 'property developers']):\n",
    "            try:\n",
    "                # Fetch contact information for each lead\n",
    "                contacts = [contact async for contact in contact_gen.fetch_contact_results(lead_result.get('link', ''))]\n",
    "                \n",
    "                if contacts and contacts[0].get('email'):\n",
    "                    lead_result.update(contacts[0])\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                print(lead_result)\n",
    "            except Exception as e:\n",
    "                contact_gen.logger.error(\n",
    "                    f\"Error processing {lead_result['link']}: {str(e)}\"\n",
    "                )\n",
    "                continue\n",
    "        return lead_result\n",
    "\n",
    "    except Exception as e:\n",
    "        contact_gen.logger.error(f\"Main function error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeadGenerator:\n",
    "    def __init__(self, token: str):\n",
    "        self.client = ApifyClientAsync(token)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    async def fetch_search_results(self, keywords: List[str]) -> List[Dict]:\n",
    "        query = \"\\n\".join(keywords)\n",
    "        run_input = {\n",
    "            \"queries\": query,\n",
    "            \"resultsPerPage\": 2,\n",
    "            \"maxPagesPerQuery\": 1,\n",
    "            \"languageCode\": \"de\",\n",
    "            \"countryCode\": 'de',\n",
    "        }\n",
    "        try:\n",
    "            actor_client = self.client.actor('apify/google-search-scraper')\n",
    "            call_result = await actor_client.call(run_input=run_input)\n",
    "            \n",
    "            if not call_result:\n",
    "                raise ValueError('Search actor run failed')\n",
    "                \n",
    "            dataset_client = self.client.dataset(call_result['defaultDatasetId'])\n",
    "            results = []\n",
    "            async for item in dataset_client.iterate_items():\n",
    "                for result in item.get('organicResults', []):\n",
    "                    results.append({\n",
    "                        'title': result.get('title', ''),\n",
    "                        'link': result.get('url', ''),\n",
    "                        'description': result.get('description', ''),\n",
    "                    })\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error fetching search results: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "class ContactGenerator:\n",
    "    def __init__(self, token: str):\n",
    "        self.client = ApifyClientAsync(token)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    async def fetch_contact_results(self, url: str) -> Optional[pd.DataFrame]:\n",
    "        run_input = {\n",
    "            \"startUrls\": [{\"url\": url}],\n",
    "            \"maxRequestsPerStartUrl\": 1,\n",
    "            \"maxDepth\": 2,\n",
    "            \"maxRequests\": 9999999,\n",
    "            \"sameDomain\": True,\n",
    "            \"considerChildFrames\": True,\n",
    "            \"useBrowser\": False,\n",
    "            \"waitUntil\": \"domcontentloaded\",\n",
    "            \"proxyConfig\": {\"useApifyProxy\": True},\n",
    "        }\n",
    "        try:\n",
    "            actor_client = self.client.actor('vdrmota/contact-info-scraper')\n",
    "            call_result = await actor_client.call(run_input=run_input)\n",
    "            \n",
    "            if not call_result:\n",
    "                raise ValueError('Search actor run failed')\n",
    "                \n",
    "            dataset_client = self.client.dataset(call_result['defaultDatasetId'])\n",
    "            items_list = await dataset_client.list_items()\n",
    "            items_data = [item.get('data') for item in items_list.items]\n",
    "            df = pd.DataFrame(items_data) if items_data else None\n",
    "            return df if df is not None and not df.empty else None\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error fetching contact results: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "async def main():\n",
    "    token = os.getenv('APIFY_KEY')\n",
    "    lead_gen = LeadGenerator(token)\n",
    "    contact_gen = ContactGenerator(token)\n",
    "    \n",
    "    try:\n",
    "        leads = await lead_gen.fetch_search_results(['real estate'])\n",
    "        results_table = []\n",
    "        for lead_result in leads:\n",
    "            try:\n",
    "                contact_df = await contact_gen.fetch_contact_results(lead_result['link'])\n",
    "                if contact_df is not None and 'emails' in contact_df.columns:\n",
    "                    results_table.append(contact_df['emails'][0])\n",
    "                    print(results_table)\n",
    "            except Exception as e:\n",
    "                contact_gen.logger.error(\n",
    "                    f\"Error processing {lead_result['link']}: {str(e)}\"\n",
    "                )\n",
    "        return pd.DataFrame(results_table, columns=['email']) if results_table else None\n",
    "    except Exception as e:\n",
    "        contact_gen.logger.error(f\"Main function error: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await main()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from apify_client import ApifyClientAsync\n",
    "import ollama\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Optional\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "class LeadPipeline:\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.apify_token = os.getenv('APIFY_TOKEN')\n",
    "        self.email_config = {\n",
    "            'sender': os.getenv('SENDER_EMAIL'),\n",
    "            'password': os.getenv('EMAIL_PASSWORD'),\n",
    "            'smtp_server': 'smtp.gmail.com',\n",
    "            'port': 465\n",
    "        }\n",
    "        \n",
    "    def setup_logging(self):\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "    \n",
    "    async def fetch_leads(self, keywords: List[str]) -> Optional[pd.DataFrame]:\n",
    "        client = ApifyClientAsync(self.apify_token)\n",
    "        scraper = LeadScraper(client)\n",
    "        try:\n",
    "            leads_df = await scraper.get_leads(keywords)\n",
    "            return leads_df\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error fetching leads: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def generate_email_content(self, prospect_details: str) -> Dict[str, str]:\n",
    "        template = f\"\"\"\n",
    "        You are a professional prospector reaching out to a potential client. Using the details below, \n",
    "        generate a personalized email outreach message in German.\n",
    "        PROSPECTOR DETAILS:\n",
    "        -------------------\n",
    "        Website: Expose´profi.de\n",
    "        Company Name: Expose´Profi\n",
    "        Description: The requirements of the real estate market and the demands of customers are constantly changing. \n",
    "                    As a property developer or real estate agent, you must always have the right solutions ready to successfully meet both sides' needs.\n",
    "                    Abstract drawings, floor plans, and sketches are no longer sufficient to present a project attractively. \n",
    "                    Prospective buyers want to see an emotional representation and receive comprehensive advice about their visions. \n",
    "                    As an innovation leader in 3D visualization of real estate, we accompany you during the planning phase of your new building project.\n",
    "                    We help you present your brand successfully and stand out from the competition with high-quality 3D visualizations.\n",
    "                    We are both innovative and experienced, following developments in real estate marketing closely. \n",
    "                    In our internal processes, we rely on the latest technologies in 3D modeling. Tasteful visualizations are perfect for your sales in online and offline marketing: on real estate websites, in exposés, printed materials, social media, etc.\n",
    "        PROSPECT DETAILS:\n",
    "        -----------------\n",
    "        {prospect_details}\n",
    "        EMAIL REQUIREMENTS:\n",
    "        -------------------\n",
    "        - Tone: Professional and friendly.\n",
    "        - Content: Concise and to the point.\n",
    "        - Must clearly state how our service benefits their project or business.\n",
    "        - Ending: Include a polite sign-off with your contact details.\n",
    "        OUTPUT FORMAT:\n",
    "        --------------\n",
    "        Return a JSON object with exactly two keys: \"Subject\" and \"Body\". Their values must be strings.\n",
    "        Do not include any extra text or commentary.\n",
    "        Generate the email message in German with a complete subject line and body using the details provided.\n",
    "        Output: {{\n",
    "            \"Subject\": \"subject of the email\",\n",
    "            \"Body\": \"body of the email\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = ollama.generate(model='llama3.2:latest', prompt=template)\n",
    "            result = response['response']\n",
    "            return {\n",
    "                'subject': result['Subject'],\n",
    "                'body': result['Body']\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error generating email content: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def send_email(self, recipient: str, subject: str, body: str) -> bool:\n",
    "        if not self.email_config['sender'] or not self.email_config['password']:\n",
    "            self.logger.error(\"Email credentials missing\")\n",
    "            return False\n",
    "            \n",
    "        msg = MIMEMultipart()\n",
    "        msg['From'] = self.email_config['sender']\n",
    "        msg['To'] = recipient\n",
    "        msg['Subject'] = subject\n",
    "        msg.attach(MIMEText(body, 'plain'))\n",
    "        \n",
    "        try:\n",
    "            with smtplib.SMTP_SSL(\n",
    "                self.email_config['smtp_server'],\n",
    "                self.email_config['port']\n",
    "            ) as server:\n",
    "                server.login(\n",
    "                    self.email_config['sender'],\n",
    "                    self.email_config['password']\n",
    "                )\n",
    "                server.send_message(msg)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error sending email: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    async def process_leads(self, keywords: List[str]) -> int:\n",
    "        \"\"\"Main pipeline function that orchestrates the entire process\"\"\"\n",
    "        leads_df = await self.fetch_leads(keywords)\n",
    "        if leads_df is None:\n",
    "            self.logger.error(\"Failed to fetch leads\")\n",
    "            return 0\n",
    "            \n",
    "        sent_count = 0\n",
    "        for _, lead in leads_df.iterrows():\n",
    "            prospect_details = f\"\"\"\n",
    "            Company Name: {lead.get('title', '')}\n",
    "            Website: {lead.get('link', '')}\n",
    "            Description: {lead.get('description', '')}\n",
    "            \"\"\"\n",
    "            \n",
    "            # Generate email content\n",
    "            email_data = self.generate_email_content(prospect_details)\n",
    "            if not email_data:\n",
    "                continue\n",
    "                \n",
    "            # Send email\n",
    "            success = self.send_email(\n",
    "                lead.get('email', ''),\n",
    "                email_data['subject'],\n",
    "                email_data['body']\n",
    "            )\n",
    "            if success:\n",
    "                sent_count += 1\n",
    "                \n",
    "        return sent_count\n",
    "\n",
    "async def main():\n",
    "    pipeline = LeadPipeline()\n",
    "    pipeline.setup_logging()\n",
    "    \n",
    "    keywords = ['real estate agents', 'construction companies']\n",
    "    sent_emails = await pipeline.process_leads(keywords)\n",
    "    print(f\"Successfully sent emails to {sent_emails} recipients\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
